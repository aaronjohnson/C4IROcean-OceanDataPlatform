{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geospatial Analysis with H3 Aggregation\n",
    "\n",
    "This notebook demonstrates geospatial analysis capabilities of the Ocean Data Platform, including spatial filtering and H3 hexagonal grid aggregation.\n",
    "\n",
    "**What you'll learn:**\n",
    "- Query data using geospatial filters (within, intersects, contains)\n",
    "- Aggregate data using H3 hexagonal grids\n",
    "- Visualize spatial distributions on interactive maps\n",
    "\n",
    "**Why H3?**\n",
    "\n",
    "[H3](https://h3geo.org/) is Uber's hexagonal hierarchical spatial index. Benefits:\n",
    "- Uniform cell shapes (unlike lat/lon grids)\n",
    "- Multiple resolution levels (0-15)\n",
    "- Efficient for spatial aggregation and analysis\n",
    "\n",
    "**Prerequisites:**\n",
    "- Running in ODP Workspace (auto-authenticated)\n",
    "- Completed `01_catalog_discovery.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. Setup"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from odp.client import Client\nfrom IPython.display import display\nimport pandas as pd\nimport numpy as np\nimport subprocess\nimport sys\n\n# Initialize ODP client\nclient = Client()\n\n# Auto-install visualization packages if missing\ndef ensure_package(package_name, import_name=None):\n    \"\"\"Install package if not available.\"\"\"\n    import_name = import_name or package_name\n    try:\n        __import__(import_name)\n        return True\n    except ImportError:\n        print(f\"Installing {package_name}...\")\n        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package_name])\n        return True\n\n# Install and import visualization packages\ntry:\n    ensure_package(\"folium\")\n    ensure_package(\"h3\")\n    import folium\n    from folium.plugins import HeatMap\n    import h3\n    HAS_FOLIUM = True\n    print(\"Folium and h3 ready for mapping\")\nexcept Exception as e:\n    HAS_FOLIUM = False\n    print(f\"Visualization packages unavailable: {e}\")\n\ntry:\n    ensure_package(\"matplotlib\")\n    import matplotlib.pyplot as plt\n    HAS_MPL = True\nexcept:\n    HAS_MPL = False\n\nprint(\"Client initialized\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Connect to Dataset\n",
    "\n",
    "We'll use the PGS Biota dataset which contains marine mammal and turtle observations with geographic coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# PGS Biota dataset - TABULAR access\n# Note: This UUID doesn't appear in STAC catalog but works via SDK\n# See debug cell below for investigation of TABULAR vs FILE UUIDs\nDATASET_ID = \"1d801817-742b-4867-82cf-5597673524eb\"\n\ndataset = client.dataset(DATASET_ID)\nschema = dataset.table.schema()\n\nif schema:\n    print(f\"Connected to TABULAR dataset\")\n    print(f\"Columns: {[f.name for f in schema]}\")\n    stats = dataset.table.stats()\n    if stats:\n        print(f\"Rows: {stats.num_rows:,}\")\nelse:\n    print(\"Dataset not accessible as tabular. Run debug cell below to investigate.\")"
  },
  {
   "cell_type": "code",
   "source": "# DEBUG: Test if old and new UUIDs represent different access patterns\n# Hypothesis: Same data may have separate TABULAR and FILE UUIDs\n\nold_uuid = \"1d801817-742b-4867-82cf-5597673524eb\"  # Original PGS Biota\nnew_uuid = \"b960c80e-7ead-47af-b6c8-e92a9b5ac659\"  # PGS Brazil - Biota and Physics\n\nprint(\"Testing UUID access patterns...\\n\")\n\nfor label, uuid in [(\"Old UUID\", old_uuid), (\"New UUID\", new_uuid)]:\n    try:\n        ds = client.dataset(uuid)\n        schema = ds.table.schema()\n        if schema:\n            stats = ds.table.stats()\n            rows = stats.num_rows if stats else \"?\"\n            print(f\"{label}: TABULAR ({rows} rows)\")\n            print(f\"  Columns: {[f.name for f in schema][:5]}...\")\n            # If tabular, use this one\n            if label == \"Old UUID\":\n                DATASET_ID = uuid\n                dataset = ds\n                print(f\"  → Using this dataset\")\n        else:\n            files = ds.files.list()\n            print(f\"{label}: FILE ({len(files)} files)\")\n    except Exception as e:\n        print(f\"{label}: Error - {str(e)[:50]}\")\n    print()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Geospatial Filtering\n",
    "\n",
    "ODP supports three spatial operators:\n",
    "- **within**: Points/geometries fully inside a polygon\n",
    "- **intersects**: Any overlap with a polygon\n",
    "- **contains**: Polygon contains another geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a region of interest - Brazilian coast (where PGS data is located)\n",
    "brazil_coast = \"POLYGON((-48 -28, -32 -28, -32 0, -48 0, -48 -28))\"\n",
    "\n",
    "# Query data within the region\n",
    "# Note: Adjust geometry column name based on your dataset schema\n",
    "GEOMETRY_COL = \"footprintWKT\"  # For PGS Biota dataset\n",
    "\n",
    "try:\n",
    "    df = dataset.table.select(\n",
    "        f\"{GEOMETRY_COL} within $area\",\n",
    "        vars={\"area\": brazil_coast}\n",
    "    ).all(max_rows=10000).dataframe()\n",
    "    \n",
    "    print(f\"Found {len(df)} observations in region\")\n",
    "    print(f\"\\nColumns: {list(df.columns)}\")\n",
    "    df.head()\n",
    "except Exception as e:\n",
    "    print(f\"Query error: {e}\")\n",
    "    print(\"\\nTrying without spatial filter...\")\n",
    "    df = dataset.table.select().all(max_rows=1000).dataframe()\n",
    "    print(f\"Loaded {len(df)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the data\n",
    "if 'scientificName' in df.columns:\n",
    "    print(\"Species observed:\")\n",
    "    print(df['scientificName'].value_counts().head(10))\n",
    "\n",
    "if 'decimalLatitude' in df.columns and 'decimalLongitude' in df.columns:\n",
    "    print(f\"\\nLatitude range: {df['decimalLatitude'].min():.2f} to {df['decimalLatitude'].max():.2f}\")\n",
    "    print(f\"Longitude range: {df['decimalLongitude'].min():.2f} to {df['decimalLongitude'].max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. H3 Hexagonal Aggregation\n",
    "\n",
    "H3 aggregation groups data into hexagonal cells at a specified resolution (0-15).\n",
    "\n",
    "| Resolution | Avg Hex Area | Use Case |\n",
    "|------------|--------------|----------|\n",
    "| 0 | 4,357,449 km² | Continental |\n",
    "| 3 | 12,393 km² | Regional |\n",
    "| 5 | 253 km² | Local |\n",
    "| 7 | 5.16 km² | Detailed |\n",
    "| 9 | 0.1 km² | Fine-grained |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Aggregate observations by H3 hexagon\n# Resolution 5 gives ~250 km² hexagons - good for regional patterns\nH3_RESOLUTION = 5\n\n# Handle different h3 library versions (v3 vs v4 API)\ndef get_h3_cell(lat, lon, res):\n    try:\n        return h3.latlng_to_cell(lat, lon, res)  # v4+ API\n    except AttributeError:\n        return h3.geo_to_h3(lat, lon, res)  # v3 API\n\n# NOTE: Server-side H3 aggregation is not yet compatible with visualization.\n# The ODP API's h3() function returns internal indices, not H3 cell ID strings.\n# Using client-side aggregation until server-side returns proper H3 hex strings.\n# See: proposals/server_side_h3_aggregation.md for discussion.\n\nif HAS_FOLIUM and 'decimalLatitude' in df.columns:\n    print(\"Computing H3 cells client-side...\")\n    print(f\"(Server-side H3 returns indices, not hex IDs - see proposals/server_side_h3_aggregation.md)\")\n    \n    df['h3_cell'] = df.apply(\n        lambda row: get_h3_cell(row['decimalLatitude'], row['decimalLongitude'], H3_RESOLUTION)\n        if pd.notna(row['decimalLatitude']) and pd.notna(row['decimalLongitude']) else None,\n        axis=1\n    )\n    \n    h3_agg = df.groupby('h3_cell').size().reset_index(name='count')\n    h3_agg = h3_agg[h3_agg['h3_cell'].notna()]\n    \n    print(f\"H3 aggregation: {len(h3_agg)} hexagonal cells\")\n    print(f\"\\nTop 10 cells by observation count:\")\n    print(h3_agg.nlargest(10, 'count'))\nelse:\n    h3_agg = None\n    print(\"H3 aggregation requires h3 library and coordinate columns\")"
  },
  {
   "cell_type": "code",
   "source": "# DEBUG: Investigate server-side H3 aggregation response\n# Uncomment to see what the ODP API returns for h3() group_by\n\n# try:\n#     h3_server = dataset.table.aggregate(\n#         group_by=f\"h3({GEOMETRY_COL}, {H3_RESOLUTION})\",\n#         filter=f\"{GEOMETRY_COL} IS NOT NULL\",\n#         aggr={\"occurrenceID\": \"count\"}\n#     )\n#     print(\"Server-side H3 aggregation result:\")\n#     print(f\"Shape: {h3_server.shape}\")\n#     print(f\"Columns: {list(h3_server.columns)}\")\n#     print(f\"Dtypes:\\n{h3_server.dtypes}\")\n#     print(f\"\\nFirst 10 rows:\\n{h3_server.head(10)}\")\n#     print(f\"\\nSample values from first column: {h3_server.iloc[:5, 0].tolist()}\")\n# except Exception as e:\n#     print(f\"Server-side H3 error: {e}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize on Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "if HAS_FOLIUM and 'decimalLatitude' in df.columns:\n    # Calculate map center\n    center_lat = df['decimalLatitude'].mean()\n    center_lon = df['decimalLongitude'].mean()\n    \n    # Create base map\n    m = folium.Map(location=[center_lat, center_lon], zoom_start=5)\n    \n    # Add observation points\n    for _, row in df.head(500).iterrows():  # Limit for performance\n        if pd.notna(row['decimalLatitude']) and pd.notna(row['decimalLongitude']):\n            folium.CircleMarker(\n                location=[row['decimalLatitude'], row['decimalLongitude']],\n                radius=3,\n                color='blue',\n                fill=True,\n                popup=row.get('scientificName', 'Unknown')\n            ).add_to(m)\n    \n    print(f\"Map centered at ({center_lat:.2f}, {center_lon:.2f})\")\n    print(f\"Showing {min(500, len(df))} observation points\")\n    display(m)\nelse:\n    print(\"Folium not available or no coordinate columns found.\")\n    print(\"Install folium: pip install folium\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Visualize H3 hexagons\nif HAS_FOLIUM and h3_agg is not None:\n    # Handle different h3 library versions\n    def get_h3_boundary(hex_id):\n        try:\n            return h3.cell_to_boundary(hex_id)  # v4+ API\n        except AttributeError:\n            return h3.h3_to_geo_boundary(hex_id, geo_json=False)  # v3 API\n    \n    m_hex = folium.Map(location=[center_lat, center_lon], zoom_start=5)\n    \n    # Plot top 100 hexagons by count\n    for _, row in h3_agg.nlargest(100, 'count').iterrows():\n        hex_id = row['h3_cell']\n        count = row['count']\n        \n        boundary = get_h3_boundary(hex_id)\n        coords = [[lat, lng] for lat, lng in boundary]\n        \n        # Color based on count\n        color = 'red' if count > 10 else 'orange' if count > 5 else 'yellow'\n        \n        folium.Polygon(\n            locations=coords,\n            color=color,\n            fill=True,\n            fill_opacity=0.4,\n            popup=f\"Count: {count}\"\n        ).add_to(m_hex)\n    \n    print(\"H3 hexagon map (color = observation density)\")\n    display(m_hex)\nelse:\n    print(\"H3 visualization requires successful aggregation in previous cell\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Aggregation with Statistics\n",
    "\n",
    "Beyond counting, aggregate other statistics per hexagon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Aggregate multiple statistics\n# Example: If dataset has depth data\nif 'minimumDepthInMeters' in df.columns:\n    try:\n        depth_agg = dataset.table.aggregate(\n            group_by=f\"h3({GEOMETRY_COL}, {H3_RESOLUTION})\",\n            filter=f\"{GEOMETRY_COL} IS NOT NULL AND minimumDepthInMeters IS NOT NULL\",\n            aggr={\n                \"minimumDepthInMeters\": \"mean\",\n                \"occurrenceID\": \"count\"\n            }\n        )\n        print(\"Depth statistics by H3 cell:\")\n        print(f\"Columns returned: {list(depth_agg.columns)}\")\n        # Sort by count column (name may vary)\n        count_col = [c for c in depth_agg.columns if 'count' in c.lower() or c == 'occurrenceID']\n        if count_col:\n            print(depth_agg.sort_values(count_col[0], ascending=False).head(10))\n        else:\n            print(depth_agg.head(10))\n    except Exception as e:\n        print(f\"Aggregation error: {e}\")\nelse:\n    print(\"No depth column in this dataset\")\n    print(f\"Available columns: {list(df.columns)}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Aggregate by species within region\nif 'scientificName' in df.columns:\n    try:\n        species_agg = dataset.table.aggregate(\n            group_by=\"scientificName\",\n            filter=f\"{GEOMETRY_COL} IS NOT NULL AND scientificName IS NOT NULL\",\n            aggr={\n                \"occurrenceID\": \"count\"\n            }\n        )\n        print(\"Observations by species:\")\n        print(f\"Columns returned: {list(species_agg.columns)}\")\n        # Sort by count column (name may vary)\n        count_col = [c for c in species_agg.columns if 'count' in c.lower() or c == 'occurrenceID']\n        if count_col:\n            print(species_agg.sort_values(count_col[0], ascending=False).head(15))\n        else:\n            print(species_agg.head(15))\n    except Exception as e:\n        print(f\"Aggregation error: {e}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Multi-Resolution Analysis\n",
    "\n",
    "Compare patterns at different H3 resolutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Compare resolutions\nif HAS_FOLIUM and 'decimalLatitude' in df.columns:\n    # Handle different h3 library versions\n    def get_h3_cell(lat, lon, res):\n        try:\n            return h3.latlng_to_cell(lat, lon, res)  # v4+ API\n        except AttributeError:\n            return h3.geo_to_h3(lat, lon, res)  # v3 API\n    \n    resolutions = [3, 5, 7]\n    \n    for res in resolutions:\n        df[f'h3_res{res}'] = df.apply(\n            lambda row, r=res: get_h3_cell(\n                row['decimalLatitude'], \n                row['decimalLongitude'], \n                r\n            ) if pd.notna(row['decimalLatitude']) else None,\n            axis=1\n        )\n        unique_cells = df[f'h3_res{res}'].nunique()\n        print(f\"Resolution {res}: {unique_cells} unique cells\")\nelse:\n    print(\"Requires coordinate columns and h3 library\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Summary\n\nThis notebook demonstrated:\n\n1. **Geospatial Filtering**: Query data using `within`, `intersects`, `contains` operators with WKT polygons\n2. **H3 Aggregation**: Group data into hexagonal cells at configurable resolutions\n3. **Map Visualization**: Display observations and hex patterns on interactive maps\n4. **Statistical Aggregation**: Calculate metrics (count, mean, etc.) per spatial cell\n5. **Multi-Resolution**: Compare patterns at different spatial scales\n\n## Next Steps\n\n- **03_data_pipeline.ipynb**: Ingest files and transform into tabular data\n- **04_multi_dataset_join.ipynb**: Combine multiple datasets for analysis\n\n## Resources\n\n- [H3 Documentation](https://h3geo.org/docs/)\n- [ODP Python SDK - Aggregation](https://docs.hubocean.earth/python_sdk/intro/)\n- [Folium Documentation](https://python-visualization.github.io/folium/)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}