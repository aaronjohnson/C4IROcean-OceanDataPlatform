{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geospatial Analysis with H3 Aggregation\n",
    "\n",
    "This notebook demonstrates geospatial analysis capabilities of the Ocean Data Platform, including spatial filtering and H3 hexagonal grid aggregation.\n",
    "\n",
    "**What you'll learn:**\n",
    "- Query data using geospatial filters (within, intersects, contains)\n",
    "- Aggregate data using H3 hexagonal grids\n",
    "- Visualize spatial distributions on interactive maps\n",
    "\n",
    "**Why H3?**\n",
    "\n",
    "[H3](https://h3geo.org/) is Uber's hexagonal hierarchical spatial index. Benefits:\n",
    "- Uniform cell shapes (unlike lat/lon grids)\n",
    "- Multiple resolution levels (0-15)\n",
    "- Efficient for spatial aggregation and analysis\n",
    "\n",
    "**Prerequisites:**\n",
    "- Running in ODP Workspace (auto-authenticated)\n",
    "- Completed `01_catalog_discovery.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. Setup"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from odp.client import Client\nimport pandas as pd\nimport numpy as np\nimport subprocess\nimport sys\n\n# Initialize ODP client\nclient = Client()\n\n# Auto-install visualization packages if missing\ndef ensure_package(package_name, import_name=None):\n    \"\"\"Install package if not available.\"\"\"\n    import_name = import_name or package_name\n    try:\n        __import__(import_name)\n        return True\n    except ImportError:\n        print(f\"Installing {package_name}...\")\n        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package_name])\n        return True\n\n# Install and import visualization packages\ntry:\n    ensure_package(\"folium\")\n    ensure_package(\"h3\")\n    import folium\n    from folium.plugins import HeatMap\n    import h3\n    HAS_FOLIUM = True\n    print(\"Folium and h3 ready for mapping\")\nexcept Exception as e:\n    HAS_FOLIUM = False\n    print(f\"Visualization packages unavailable: {e}\")\n\ntry:\n    ensure_package(\"matplotlib\")\n    import matplotlib.pyplot as plt\n    HAS_MPL = True\nexcept:\n    HAS_MPL = False\n\nprint(\"Client initialized\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Connect to Dataset\n",
    "\n",
    "We'll use the PGS Biota dataset which contains marine mammal and turtle observations with geographic coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PGS Biota Data - Mammal and Turtle Observations (from SDK reference)\n",
    "DATASET_ID = \"1d801817-742b-4867-82cf-5597673524eb\"\n",
    "\n",
    "# Alternative: Try GLODAP for ocean chemistry data\n",
    "# DATASET_ID = \"15dac249-4e3d-474b-a246-ba95cffc8807\"\n",
    "\n",
    "dataset = client.dataset(DATASET_ID)\n",
    "\n",
    "# Check if tabular\n",
    "schema = dataset.table.schema()\n",
    "if schema:\n",
    "    print(f\"Connected to tabular dataset\")\n",
    "    print(f\"Columns: {[f.name for f in schema]}\")\n",
    "    \n",
    "    stats = dataset.table.stats()\n",
    "    if stats:\n",
    "        print(f\"\\nRows: {stats.num_rows:,}\")\n",
    "else:\n",
    "    print(\"Dataset is file-based, not tabular.\")\n",
    "    print(\"Try a different DATASET_ID with tabular data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Geospatial Filtering\n",
    "\n",
    "ODP supports three spatial operators:\n",
    "- **within**: Points/geometries fully inside a polygon\n",
    "- **intersects**: Any overlap with a polygon\n",
    "- **contains**: Polygon contains another geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a region of interest - Brazilian coast (where PGS data is located)\n",
    "brazil_coast = \"POLYGON((-48 -28, -32 -28, -32 0, -48 0, -48 -28))\"\n",
    "\n",
    "# Query data within the region\n",
    "# Note: Adjust geometry column name based on your dataset schema\n",
    "GEOMETRY_COL = \"footprintWKT\"  # For PGS Biota dataset\n",
    "\n",
    "try:\n",
    "    df = dataset.table.select(\n",
    "        f\"{GEOMETRY_COL} within $area\",\n",
    "        vars={\"area\": brazil_coast}\n",
    "    ).all(max_rows=10000).dataframe()\n",
    "    \n",
    "    print(f\"Found {len(df)} observations in region\")\n",
    "    print(f\"\\nColumns: {list(df.columns)}\")\n",
    "    df.head()\n",
    "except Exception as e:\n",
    "    print(f\"Query error: {e}\")\n",
    "    print(\"\\nTrying without spatial filter...\")\n",
    "    df = dataset.table.select().all(max_rows=1000).dataframe()\n",
    "    print(f\"Loaded {len(df)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the data\n",
    "if 'scientificName' in df.columns:\n",
    "    print(\"Species observed:\")\n",
    "    print(df['scientificName'].value_counts().head(10))\n",
    "\n",
    "if 'decimalLatitude' in df.columns and 'decimalLongitude' in df.columns:\n",
    "    print(f\"\\nLatitude range: {df['decimalLatitude'].min():.2f} to {df['decimalLatitude'].max():.2f}\")\n",
    "    print(f\"Longitude range: {df['decimalLongitude'].min():.2f} to {df['decimalLongitude'].max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. H3 Hexagonal Aggregation\n",
    "\n",
    "H3 aggregation groups data into hexagonal cells at a specified resolution (0-15).\n",
    "\n",
    "| Resolution | Avg Hex Area | Use Case |\n",
    "|------------|--------------|----------|\n",
    "| 0 | 4,357,449 km² | Continental |\n",
    "| 3 | 12,393 km² | Regional |\n",
    "| 5 | 253 km² | Local |\n",
    "| 7 | 5.16 km² | Detailed |\n",
    "| 9 | 0.1 km² | Fine-grained |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Aggregate observations by H3 hexagon\n# Resolution 5 gives ~250 km² hexagons - good for regional patterns\nH3_RESOLUTION = 5\n\ntry:\n    h3_agg = dataset.table.aggregate(\n        group_by=f\"h3({GEOMETRY_COL}, {H3_RESOLUTION})\",\n        filter=f\"{GEOMETRY_COL} IS NOT NULL\",\n        aggr={\n            \"occurrenceID\": \"count\"\n        }\n    )\n    \n    print(f\"Aggregated into {len(h3_agg)} hexagonal cells\")\n    print(f\"Columns: {list(h3_agg.columns)}\")\n    \n    # Rename columns for clarity: '*' is H3 cell, aggregated field has the count\n    h3_agg.columns = ['h3_cell', 'count']\n    \n    h3_agg_sorted = h3_agg.sort_values('count', ascending=False)\n    print(f\"\\nTop 10 cells by observation count:\")\n    print(h3_agg_sorted.head(10))\n    \nexcept Exception as e:\n    print(f\"H3 aggregation error: {e}\")\n    print(\"\\nFalling back to client-side H3 aggregation...\")\n    h3_agg = None"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Client-side H3 aggregation (fallback if server-side fails)\nif h3_agg is None and HAS_FOLIUM and 'decimalLatitude' in df.columns:\n    # Handle different h3 library versions\n    def get_h3_cell(lat, lon, res):\n        try:\n            return h3.latlng_to_cell(lat, lon, res)  # v4+ API\n        except AttributeError:\n            return h3.geo_to_h3(lat, lon, res)  # v3 API\n    \n    # Generate H3 indices for each point\n    df['h3_index'] = df.apply(\n        lambda row: get_h3_cell(\n            row['decimalLatitude'], \n            row['decimalLongitude'], \n            H3_RESOLUTION\n        ) if pd.notna(row['decimalLatitude']) and pd.notna(row['decimalLongitude']) else None,\n        axis=1\n    )\n    \n    # Aggregate by H3 cell\n    h3_counts = df.groupby('h3_index').size().reset_index(name='count')\n    h3_counts = h3_counts[h3_counts['h3_index'].notna()]\n    \n    print(f\"Client-side H3 aggregation: {len(h3_counts)} cells\")\n    print(h3_counts.sort_values('count', ascending=False).head(10))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize on Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAS_FOLIUM and 'decimalLatitude' in df.columns:\n",
    "    # Calculate map center\n",
    "    center_lat = df['decimalLatitude'].mean()\n",
    "    center_lon = df['decimalLongitude'].mean()\n",
    "    \n",
    "    # Create base map\n",
    "    m = folium.Map(location=[center_lat, center_lon], zoom_start=5)\n",
    "    \n",
    "    # Add observation points\n",
    "    for _, row in df.head(500).iterrows():  # Limit for performance\n",
    "        if pd.notna(row['decimalLatitude']) and pd.notna(row['decimalLongitude']):\n",
    "            folium.CircleMarker(\n",
    "                location=[row['decimalLatitude'], row['decimalLongitude']],\n",
    "                radius=3,\n",
    "                color='blue',\n",
    "                fill=True,\n",
    "                popup=row.get('scientificName', 'Unknown')\n",
    "            ).add_to(m)\n",
    "    \n",
    "    print(f\"Map centered at ({center_lat:.2f}, {center_lon:.2f})\")\n",
    "    print(f\"Showing {min(500, len(df))} observation points\")\n",
    "    m\n",
    "else:\n",
    "    print(\"Folium not available or no coordinate columns found.\")\n",
    "    print(\"Install folium: pip install folium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Visualize H3 hexagons\n# Use server-side result (h3_agg) or client-side result (h3_counts)\nh3_data = h3_agg if h3_agg is not None else (h3_counts if 'h3_counts' in dir() else None)\n\nif HAS_FOLIUM and h3_data is not None:\n    # Handle different h3 library versions\n    def get_h3_boundary(hex_id):\n        try:\n            return h3.cell_to_boundary(hex_id)  # v4+ API\n        except AttributeError:\n            return h3.h3_to_geo_boundary(hex_id, geo_json=False)  # v3 API\n    \n    # Determine column names based on source\n    hex_col = 'h3_cell' if 'h3_cell' in h3_data.columns else 'h3_index'\n    count_col = 'count'\n    \n    m_hex = folium.Map(location=[center_lat, center_lon], zoom_start=5)\n    \n    # Get hex boundaries and add to map\n    for _, row in h3_data.nlargest(100, count_col).iterrows():\n        hex_id = row[hex_col]\n        count = row[count_col]\n        \n        if pd.isna(hex_id):\n            continue\n            \n        # Get hex boundary\n        boundary = get_h3_boundary(hex_id)\n        # Convert to [lat, lon] format\n        coords = [[lat, lng] for lat, lng in boundary]\n        \n        # Color based on count\n        color = 'red' if count > 10 else 'orange' if count > 5 else 'yellow'\n        \n        folium.Polygon(\n            locations=coords,\n            color=color,\n            fill=True,\n            fill_opacity=0.4,\n            popup=f\"Count: {count}\"\n        ).add_to(m_hex)\n    \n    print(\"H3 hexagon map (color = observation density)\")\n    m_hex\nelse:\n    print(\"H3 visualization requires successful aggregation in previous cells\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Aggregation with Statistics\n",
    "\n",
    "Beyond counting, aggregate other statistics per hexagon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate multiple statistics\n",
    "# Example: If dataset has depth data\n",
    "if 'minimumDepthInMeters' in df.columns:\n",
    "    try:\n",
    "        depth_agg = dataset.table.aggregate(\n",
    "            group_by=f\"h3({GEOMETRY_COL}, {H3_RESOLUTION})\",\n",
    "            filter=f\"{GEOMETRY_COL} IS NOT NULL AND minimumDepthInMeters IS NOT NULL\",\n",
    "            aggr={\n",
    "                \"minimumDepthInMeters\": \"mean\",\n",
    "                \"*\": \"count\"\n",
    "            }\n",
    "        )\n",
    "        print(\"Depth statistics by H3 cell:\")\n",
    "        print(depth_agg.sort_values('count', ascending=False).head(10))\n",
    "    except Exception as e:\n",
    "        print(f\"Aggregation error: {e}\")\n",
    "else:\n",
    "    print(\"No depth column in this dataset\")\n",
    "    print(f\"Available columns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate by species within region\n",
    "if 'scientificName' in df.columns:\n",
    "    try:\n",
    "        species_agg = dataset.table.aggregate(\n",
    "            group_by=\"scientificName\",\n",
    "            filter=f\"{GEOMETRY_COL} IS NOT NULL AND scientificName IS NOT NULL\",\n",
    "            aggr={\n",
    "                \"*\": \"count\"\n",
    "            }\n",
    "        )\n",
    "        print(\"Observations by species:\")\n",
    "        print(species_agg.sort_values('count', ascending=False).head(15))\n",
    "    except Exception as e:\n",
    "        print(f\"Aggregation error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Multi-Resolution Analysis\n",
    "\n",
    "Compare patterns at different H3 resolutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Compare resolutions\nif HAS_FOLIUM and 'decimalLatitude' in df.columns:\n    # Handle different h3 library versions\n    def get_h3_cell(lat, lon, res):\n        try:\n            return h3.latlng_to_cell(lat, lon, res)  # v4+ API\n        except AttributeError:\n            return h3.geo_to_h3(lat, lon, res)  # v3 API\n    \n    resolutions = [3, 5, 7]\n    \n    for res in resolutions:\n        df[f'h3_res{res}'] = df.apply(\n            lambda row, r=res: get_h3_cell(\n                row['decimalLatitude'], \n                row['decimalLongitude'], \n                r\n            ) if pd.notna(row['decimalLatitude']) else None,\n            axis=1\n        )\n        unique_cells = df[f'h3_res{res}'].nunique()\n        print(f\"Resolution {res}: {unique_cells} unique cells\")\nelse:\n    print(\"Requires coordinate columns and h3 library\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Summary\n\nThis notebook demonstrated:\n\n1. **Geospatial Filtering**: Query data using `within`, `intersects`, `contains` operators with WKT polygons\n2. **H3 Aggregation**: Group data into hexagonal cells at configurable resolutions\n3. **Map Visualization**: Display observations and hex patterns on interactive maps\n4. **Statistical Aggregation**: Calculate metrics (count, mean, etc.) per spatial cell\n5. **Multi-Resolution**: Compare patterns at different spatial scales\n\n## Next Steps\n\n- **03_data_pipeline.ipynb**: Ingest files and transform into tabular data\n- **04_multi_dataset_join.ipynb**: Combine multiple datasets for analysis\n\n## Resources\n\n- [H3 Documentation](https://h3geo.org/docs/)\n- [ODP Python SDK - Aggregation](https://docs.hubocean.earth/python_sdk/intro/)\n- [Folium Documentation](https://python-visualization.github.io/folium/)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}